\section{Offline Processing of the Experimental and MC Data}
\label{sec:protodune-offline}
%\subsection{Data processing}
%\label{sec:protodune-dataprocess}

The raw data collected by \pd will undergo offline processing. More broadly, the offline data
can be classified as follows:
\begin{itemize}

\item A variety of calibration data derived from experimental data (also including dedicated calibration
runs where necessary, and/or subsamples of data collected specifically for calibration
purposes during normal running conditions)

\item Processed experimental data, which may exist in several parallel branches corresponding to
different reconstruction algorithms being applied, with the purpose of evaluating the performance
of the different algorithms

\item Monte Carlo (MC) data, which will contain multiple event samples to cover various event types
and other conditions during the measurements with protoDUNE

\item Data derived from MC events, and produced with a variety of tracking and pattern recognition algorithms
in order to create a basis for the detector characterization

\end{itemize}

\noindent The production processing will likely have more than one processing step,
thus multiplying the data volume. It is desirable that the derived data would be reduced
in size with respect to the raw data in order to keep the data volume manageable.
It is thus assumed that the size of the processed data will likely be smaller than the input (the raw data). 
Given the consideration presented above, and numbers in Table\,\ref{fig:det_perf}
on page~\pageref{fig:det_perf} we will plan for
$\sim$ O(1PB) of tape storage to keep the processed data. 
For efficient processing, disk storage will be necessary
to stage a considerable portion of both raw data (inputs) and one or a few steps in processing (outputs).

Extrapolating from our previous experience running Monte Carlo for the previous DUNE MC campaigns of comparable scale,
it is estimated that  a few hundred TB of continuously available disk space will be needed. It is expected that protoDUNE will require
a few~PB of storage at Fermilab to ensure optimal data availability and  processing efficiency. 

\subsection{Prompt Processing}
In the present context, \textit{Prompt Processing} means a number of fast signal processing and reconstruction processes
(also called ``express stream'' sometimes) which process a fraction of raw data. Its main purpose is to aid in QA of the data
and produce quick calibrations which may be necessary for high quality monitoring of the detector. As one example,
calculating frequency spectra of noise and watching its level, evolution and other characteristincs is an important aspect of ensuring
the stability of the readout chain.

It is understood
that a limited number of metrics will be calculated to make the proccess as quick as possible in order to enable
the operators to take action should the QA process indicate a potential problem in the detector or the data.

The following parameters of prompt processing need to considered:
\begin{itemize}
\item Desired turnaround time.
\item Location of the computing resources utilized.
\item Fraction and type of data to be processed in this manner.
\end{itemize}

\subsection{Workload Management}
\label{sec:dune-wms}
For DUNE requirements to its Workload Management System please see the Computing Model document\,\cite{dune_computing_model}.
There are a few systems currently used by various experiments which
differ in the following aspects:
\begin{itemize}

\item Degree of integration with their corresponding data management system.

\item Depth and breadth of monitoring capabilities offered by the system to the user and to the expeiment's operations team.

\item Ability to handle complex workflows automatically.

\item Functionality to correct various error conditions and failure modes, for example ``retry'' a set of jobs that were stuck in an unfinished state
due to corrupted or otherwise missing data and other such conditions.

\end{itemize}

\noindent
At the time of writing, the DUNE Collaboration is evaluating a few existing frameworks in order to identify
a solution which works best in the context of \pd. A few examples of widely deployed WMS include:
\begin{itemize}

\item Dirac (Distributed Infrastructure with Remote Agent Control) WMS~\cite{dirac_wms} used at CERN by LHCb.

\item PanDA (``Production and Distributed Analysis'') \cite{panda_chep13}, which forms the backbone of ATLAS processing and has been used in other experiments such as AMS.
PanDA has scaled up to manage O(10$^6$) Grid jobs daily, upgraded to use a fine-grained workflow management system, added an event service to
make it easier to use short-term opportunistics resource and a host of other features. A distinguishing feature of PanDA is sophisticated and powerful
monitoring system which allows efficient troubleshooting and optimal degree of control over execution of workflows.

\item GlideinWMS \cite{glideinwms_chep13} used in CMS and a variety of projects in other disciplines via the Open Science Grid Consortium.

\item Alien \cite{alien} deployed for the Alice experiment at the LHC.

\end{itemize}

\noindent
FNAL has successfully deployed a Grid toolkit named \textit{jobsub} \cite{jobsub_chep13}, which has been used for a number of years to facilitate users' access to
Grid facilities at FNAL and at other grid sites, such as those participating in the Open Science Grid Consortium ({\tt https://www.opensciencegrid.org/}).
It integrates FNAL-local access via HTCondor facilities with GlideinWMS extensions to reach available resources elsewhere.

Where needed, \textit{jobsub} leverages the CVMFS network file system for software provisioning and the \textit{ifdh} data handling tool which integrates
with SAM, dCache, Amason S3 etc.
